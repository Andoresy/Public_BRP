240126_16_01
 start training 
{'n_encode_layers': 4, 'N_samplings': 8, 'epochs': 200, 'batch': 256, 'batch_num': 50, 'batch_verbose': 10, 'max_stacks': 3, 'max_tiers': 5, 'plus_tiers': 2, 'baseline_type': 'greedy', 'lr': 0.0001, 'warmuplr': 0.001, 'beta': 0.1, 'embed_dim': 32}